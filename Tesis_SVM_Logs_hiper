/Users/frandm/anaconda3/envs/untitled/bin/python /Users/frandm/PycharmProjects/tesis/Ironic_SVM.py
[nltk_data] Downloading package punkt to /Users/frandm/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Using TensorFlow backend.
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Fitting 3 folds for each of 1200 candidates, totalling 3600 fits
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5670483930550425, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.7077946065755449, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6949935340846112, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5639083856667898, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7098263760620613, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6948087936449289, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5620613224972294, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.6s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.6s remaining:    0.0s
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.7122275581824898, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6983188619988916, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.7s remaining:    0.0s
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5668636867380864, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7079793128925009, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6953630149639756, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5626154414480975, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7144440339859623, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6973951598004803, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5718507572958995, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6976357591429627, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6955477554036579, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5661248614702623, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.6913557443664573, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.699427304636985, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5583671961581086, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.6926486885851496, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.6962867171623869, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5620613224972294, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.6987439970446989, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.6970256789211159, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5622460288141854, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.7033616549685999, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.7057084795861814, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.555411895086812, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.7105652013298854, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.7049695178274524, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5714813446619874, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.7113040265977096, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6955477554036579, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5585519024750647, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.7000369412633912, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6931461296877887, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5640930919837458, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6954192833394902, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6916682061703306, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5683413372737348, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6980051717768748, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.691113984851284, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5709272257111193, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7057628370890284, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.701644189913172, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.5687107499076468, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.708718138160325, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6905597635322372, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5657554488363502, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.7081640192094569, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.7025678921115832, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.565016623568526, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7162910971555227, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.702383151671901, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5753601773180643, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6980051717768748, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.7010899685941252, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5618766161802734, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.6961581086073144, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.6898208017735082, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5681566309567787, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6906169190986332, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.67762793275448, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5628001477650536, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.7033616549685999, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.6979493811195271, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5672330993719985, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.6902475064647211, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.7012747090338075, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.560029553010713, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.7007757665312153, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.6957324958433401, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5701884004432951, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.7026228297007757, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6949935340846112, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5663095677872183, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.7041004802364241, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6990578237576205, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5633542667159217, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.7076099002585888, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6887123591354147, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.5598448466937569, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6978204654599187, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6879733973766857, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5633542667159217, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6985592907277429, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.7020136707925365, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.565016623568526, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.708348725526413, total=   5.6s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6973951598004803, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5676025120059106, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.7055781307720724, total=   5.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.7106964714576021, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5762837089028445, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7068710749907647, total=   4.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7084795861814152, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5613224972294052, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.7090875507942371, total=  10.9s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6948087936449289, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5657554488363502, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.7092722571111932, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.700905228154443, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5718507572958995, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.7068710749907647, total=   8.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6907445039719194, total=   5.7s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5770225341706686, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6928333949021056, total=   7.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6844633290227231, total=   7.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5842260805319542, total=   3.7s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.7077946065755449, total=   6.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6903750230925549, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5544883635020318, total=   2.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.7007757665312153, total=   5.9s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.687419176057639, total=   5.6s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5589213151089767, total=   3.4s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.7028075360177318, total=   5.9s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6892665804544614, total=   7.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5541189508681197, total=   3.9s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.7055781307720724, total=   4.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6990578237576205, total=   3.9s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5652013298854821, total=   4.4s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.7035463612855559, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6900055422131904, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5718507572958995, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6981898780938308, total=   4.6s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6898208017735082, total=   7.5s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5679719246398227, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.7048393055042482, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6966561980417514, total=   2.6s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5677872183228666, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.699113409678611, total=   7.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6805837797893959, total=   3.8s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5779460657554488, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7090875507942371, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7005357472750785, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5628001477650536, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7164758034724787, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6922224274893775, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5652013298854821, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7011451791651274, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7070016626639571, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5748060583671961, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7157369782046547, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7038610751893589, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5690801625415589, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7002216475803472, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7062627009052281, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5760990025858884, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.703731067602512, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6933308701274709, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5727742888806797, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.7031769486516439, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6927766488084242, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5674178056889546, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.698928703361655, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6829854055052651, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5700036941263391, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.7026228297007757, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6839091077036763, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5685260435906908, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.703731067602512, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6983188619988916, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5779460657554488, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.7007757665312153, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6968409384814336, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.564647210934614, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6996675286294791, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.7029373729909477, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.569264868858515, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6983745844107868, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6957324958433401, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5712966383450314, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.7100110823790173, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6929613892481065, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5578130772072405, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6957886959734023, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6962867171623869, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5613224972294052, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.7146287403029183, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6946240532052467, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5720354636128555, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7186922792759513, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7112506927766488, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5668636867380864, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.713335796084226, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6992425641973028, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5714813446619874, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.708348725526413, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7031221134306299, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5729589951976357, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7144440339859623, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.6940698318861999, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5755448836350203, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.7101957886959734, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.6924071679290597, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5567048393055043, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.7035463612855559, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.6999815259560318, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5705578130772072, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.7029922423346878, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.6992425641973028, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5687107499076468, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.7061322497229405, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.6892665804544614, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5733284078315478, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.7031769486516439, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.6948087936449289, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5768378278537126, total=   0.5s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.7028075360177318, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6973951598004803, total=   0.6s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.5635389730328777, total=   0.5s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.7063169560398965, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6959172362830224, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5698189878093831, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.7009604728481714, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.7034915943099944, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5709272257111193, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.703731067602512, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.7007204877147608, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5670483930550425, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.7065016623568526, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6872344356179567, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5714813446619874, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7094569634281492, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6850175503417698, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5620613224972294, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7159216845216106, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6848328099020876, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5629848540820096, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7199852234946436, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7108812118972844, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5683413372737348, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7137052087181381, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.701644189913172, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5701884004432951, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7052087181381603, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7027526325512655, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5681566309567787, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.6998522349464351, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.6972104193607981, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5631695603989656, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.694680458071666, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6868649547385923, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5681566309567787, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.6994828223125231, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.6763347496767043, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5607683782785371, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.6970816401920946, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.7082948457417328, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5725895825637237, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.6959734022903583, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.6824311841862184, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5762837089028445, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.7053934244551163, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6999815259560318, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5709272257111193, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.7042851865533801, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6905597635322372, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.574251939416328, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.7109346139637975, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6872344356179567, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5670483930550425, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.7024381233838197, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6931461296877887, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5609530845954932, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.698928703361655, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.699427304636985, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5703731067602512, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.7170299224233468, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6938850914465177, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5729589951976357, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.717584041374215, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.7031221134306299, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5681566309567787, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7138899150350942, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7036763347496767, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5735131141485039, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.7142593276690062, total=   4.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6833548863846296, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5620613224972294, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.7105652013298854, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6988730833179383, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5773919468045807, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.694311045437754, total=   6.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6861259929798633, total=   5.5s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5744366457332841, total=   0.4s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.7107499076468415, total=   5.9s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6966561980417514, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.569634281492427, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6843369043221278, total=   6.4s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6940698318861999, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5681566309567787, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.7005910602142593, total=   9.5s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.7060779604655459, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5749907646841522, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.7000369412633912, total=   6.8s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6787363753925735, total=  10.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.578869597340229, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6963428149242704, total=   5.7s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.7014594494734897, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5729589951976357, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6967122275581825, total=   4.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6813227415481249, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5596601403768009, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.7116734392316217, total=   3.8s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6977646406798448, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5594754340598449, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.7020687107499076, total=   3.9s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6820617033068539, total=   3.5s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5729589951976357, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6939416328038419, total=   4.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6999815259560318, total=   3.7s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5760990025858884, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7153675655707425, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.691852946610013, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5676025120059106, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7103804950129294, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6997967855163495, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5714813446619874, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7120428518655338, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7012747090338075, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5727742888806797, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7183228666420391, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7101422501385554, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5703731067602512, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7068710749907647, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6955477554036579, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5661248614702623, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.7022534170668637, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6924071679290597, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.569634281492427, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.7074251939416328, total=   0.3s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.7055237391464991, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5820096047284817, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.7065016623568526, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.7025678921115832, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5720354636128555, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.71315108976727, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6835396268243118, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5731437015145918, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6981898780938308, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6946240532052467, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5557813077207241, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.7007757665312153, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6935156105671532, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5727742888806797, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.7120428518655338, total=   0.2s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6900055422131904, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5729589951976357, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.7028075360177318, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6975799002401626, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5814554857776136, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6998522349464351, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6903750230925549, total=   0.1s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5631695603989656, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.7100110823790173, total=   0.0s
[CV] alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6857565121004988, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5722201699298116, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.7057628370890284, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6907445039719194, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5583671961581086, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7188769855929072, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6846480694624053, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5635389730328777, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.7098263760620613, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6997967855163495, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5589213151089767, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7074251939416328, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6887123591354147, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5668636867380864, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7100110823790173, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7064474413449104, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5690801625415589, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6972663465090506, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6955477554036579, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5652013298854821, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.703915773919468, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.6900055422131904, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5633542667159217, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.699298115995567, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.6809532606687604, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5729589951976357, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.7022534170668637, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.7021984112322187, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.564647210934614, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.7042851865533801, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.6946240532052467, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5733284078315478, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.7046545991872922, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6997967855163495, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5716660509789435, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.7063169560398965, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.7036763347496767, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5626154414480975, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.7111193202807536, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6872344356179567, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5762837089028445, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.7050240118212043, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6957324958433401, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5746213520502401, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.7022534170668637, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.7040458156290412, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5668636867380864, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7127816771333579, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7095880288195086, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.5712966383450314, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.7066863686738086, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6973951598004803, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.569634281492427, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.7122275581824898, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6968409384814336, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.5635389730328777, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7246028814185446, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7057084795861814, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5659401551533062, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.7072404876246767, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6983188619988916, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5609530845954932, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.6998522349464351, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.691852946610013, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5628001477650536, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6843369043221278, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.7047847773877702, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.555596601403768, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.7059475434059845, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.7073711435433216, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5624307351311415, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.6998522349464351, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.68668021429891, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5746213520502401, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.7011451791651274, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.6975799002401626, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.578684891023273, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6985592907277429, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.687419176057639, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5700036941263391, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.7063169560398965, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6938850914465177, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5615072035463613, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.7029922423346878, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6924071679290597, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.5796084226080532, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.7074251939416328, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6826159246259006, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5563354266715922, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6998522349464351, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.7042305560687234, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5688954562246029, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6928333949021056, total=   2.4s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6916682061703306, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5701884004432951, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.7076099002585888, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6942545723258822, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.569449575175471, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7094569634281492, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6922224274893775, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5611377909124492, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.7068710749907647, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6912987252909661, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5655707425193942, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.7081640192094569, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.691113984851284, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5666789804211304, total=   0.3s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6972663465090506, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6927766488084242, total=   4.7s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5703731067602512, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.7050240118212043, total=   4.9s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6839091077036763, total=   4.3s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5622460288141854, total=   2.3s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.7090875507942371, total=   4.4s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6949935340846112, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5714813446619874, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.7055781307720724, total=   5.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6977646406798448, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5668636867380864, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6954192833394902, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6842785885830408, total=   5.4s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5659401551533062, total=   1.4s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.7079793128925009, total=   2.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6872344356179567, total=   1.9s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5722201699298116, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6970816401920946, total=   2.4s
  ConvergenceWarning)
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.7042305560687234, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.579054303657185, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6941263391207979, total=   2.5s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.7084795861814152, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5644625046176579, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.7002216475803472, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6816922224274894, total=   2.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5620613224972294, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6967122275581825, total=   2.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6796600775909847, total=   2.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.560029553010713, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7026228297007757, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7038610751893589, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5605836719615811, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7063169560398965, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6905597635322372, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5755448836350203, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7046545991872922, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6986883428782561, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5633542667159217, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7024381233838197, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6920376870496951, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5757295899519763, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7155522718876985, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6981341215592093, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5676025120059106, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.7035463612855559, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6798448180306669, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5644625046176579, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.7015145917990395, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6868649547385923, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5757295899519763, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.7002216475803472, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6905597635322372, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5666789804211304, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.699298115995567, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6944393127655644, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5498707055781308, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6972663465090506, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6900055422131904, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.569634281492427, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.7007757665312153, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6955477554036579, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5816401920945696, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.7028075360177318, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.7031221134306299, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5777613594384928, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6965275212412264, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.691113984851284, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5755448836350203, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.7103804950129294, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6957324958433401, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5679719246398227, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6956039896564462, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.7049695178274524, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5764684152198005, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.712966383450314, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6988730833179383, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5677872183228666, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7057628370890284, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.706816922224275, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5735131141485039, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.7013298854820835, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6990578237576205, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5611377909124492, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7120428518655338, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7044152965084057, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5659401551533062, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.712966383450314, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7042305560687234, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5666789804211304, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.7076099002585888, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.687419176057639, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5572589582563724, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.6983745844107868, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.699427304636985, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5809013668267454, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.7166605097894349, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.6896360613338259, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5687107499076468, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.7055781307720724, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.7103269905782376, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5757295899519763, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.7031769486516439, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.7051542582671346, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5759142962689324, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.7081640192094569, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6992425641973028, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.574251939416328, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.7066863686738086, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6833548863846296, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.578869597340229, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.713335796084226, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6907445039719194, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5812707794606575, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6983745844107868, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.7051542582671346, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5720354636128555, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.7018840044329516, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.692591908368742, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5635389730328777, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7183228666420391, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7046000369480879, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5698189878093831, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7194311045437753, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6929613892481065, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5644625046176579, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7149981529368304, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6986883428782561, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5720354636128555, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7100110823790173, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.6968409384814336, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.560398965644625, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7094569634281492, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.6892665804544614, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5633542667159217, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.7072404876246767, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.6735636430814705, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5736978204654599, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6967122275581825, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6973951598004803, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5628001477650536, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.6994828223125231, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.687419176057639, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5714813446619874, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.7063169560398965, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.6937003510068354, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5760990025858884, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.7004063538973033, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.6981341215592093, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5722201699298116, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.7002216475803472, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.7071864031036393, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5760990025858884, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.7114887329146656, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6955477554036579, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5670483930550425, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.708348725526413, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6848328099020876, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5753601773180643, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.7002216475803472, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6937003510068354, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5757295899519763, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.703731067602512, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.7097727692591909, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5794237162910971, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.7101957886959734, total=   2.6s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.7031221134306299, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5731437015145918, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.7055781307720724, total=   2.6s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6977646406798448, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5733284078315478, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7153675655707425, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.7108812118972844, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5631695603989656, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.7089028444772811, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.699427304636985, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5718507572958995, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.7026228297007757, total=   2.0s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.7007204877147608, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5688954562246029, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.7026228297007757, total=   4.6s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.7012747090338075, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5716660509789435, total=   0.3s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6980051717768748, total=   4.8s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6840938481433586, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.560029553010713, total=   0.3s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.699113409678611, total=   4.3s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6868649547385923, total=   4.4s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5759142962689324, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.7046545991872922, total=   4.2s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6890818400147792, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.565016623568526, total=   0.2s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.7024381233838197, total=   4.5s
  ConvergenceWarning)
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.7036763347496767, total=   4.0s
  ConvergenceWarning)
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5757295899519763, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6891392685629849, total=   2.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6829854055052651, total=   1.9s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5725895825637237, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6972663465090506, total=   2.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6800295584703492, total=   1.9s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5775766531215367, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.7002216475803472, total=   2.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6986883428782561, total=   0.6s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5773919468045807, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.703731067602512, total=   2.1s
  ConvergenceWarning)
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6968409384814336, total=   1.9s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5661248614702623, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.7077946065755449, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=1e-05, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6763347496767043, total=   1.9s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5729589951976357, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6998522349464351, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7055237391464991, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5714813446619874, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7151828592537864, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6962867171623869, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5700036941263391, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.708533431843369, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7070016626639571, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5768378278537126, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7190616919098634, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6883428782560502, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5735131141485039, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7138899150350942, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6927766488084242, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5640930919837458, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.7090875507942371, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.7034915943099944, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5751754710011082, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6970816401920946, total=   0.3s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.7066321817845926, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5749907646841522, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.6930181012190617, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.6979493811195271, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.583302548947174, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.7013298854820835, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.688158137816368, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5683413372737348, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.7063169560398965, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.701644189913172, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5736978204654599, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.7035463612855559, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6916682061703306, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5690801625415589, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.7009604728481714, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6905597635322372, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5666789804211304, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6978204654599187, total=   0.1s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.7033068538703122, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.569634281492427, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.7077946065755449, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6800295584703492, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5807166605097894, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.7124122644994458, total=   0.0s
[CV] alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=1e-05, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.7042305560687234, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5572589582563724, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.717584041374215, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.7027526325512655, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5598448466937569, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7181381603250832, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7031221134306299, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5611377909124492, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.7125969708164019, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6975799002401626, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5579977835241965, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7164758034724787, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7010899685941252, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.565016623568526, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7070557813077207, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6938850914465177, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5177318064277798, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.523457702253417, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6144467023831517, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5201329885482083, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5495012929442187, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5882135599482726, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5125600295530107, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5701884004432951, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.6098281913910956, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.528075360177318, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5864425563354266, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.6083502678736376, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5134835611377909, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.6039896564462505, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.6074265656752263, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5535648319172516, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6895086811968969, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6861259929798633, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5493165866272627, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6920945696342815, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.7047847773877702, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5526413003324714, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6869227927595124, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6999815259560318, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5511636497968231, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6893239748799409, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6914834657306484, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5563354266715922, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6909863317325452, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.662663957140218, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5609530845954932, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7144440339859623, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7070016626639571, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.5511636497968231, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.7157369782046547, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6914834657306484, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5591060214259328, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.7107499076468415, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6855717716608165, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.5483930550424825, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7198005171776874, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.685941252540181, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5535648319172516, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.7074251939416328, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6877886569370035, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5182859253786479, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5716660509789435, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5998522076482542, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5060953084595493, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5622460288141854, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5658599667467209, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.4883635020317695, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5668636867380864, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.592277849621282, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5136682674547469, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5803472478758773, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5965268797339738, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5077576653121537, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5875507942371629, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.6007759098466654, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5652013298854821, total=   0.6s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6950498707055781, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6996120450766673, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5446989287033617, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6998522349464351, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6779974136338445, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5495012929442187, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6972663465090506, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.7018289303528542, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.564647210934614, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6880310306612486, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6872344356179567, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5598448466937569, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6749168821573698, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6868649547385923, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5670483930550425, total=   3.8s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6869227927595124, total=   3.7s
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6951782745242934, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5629848540820096, total=   3.9s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6957886959734023, total=   5.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6909292444116018, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5655707425193942, total=   4.3s
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6950498707055781, total=   3.9s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6794753371513024, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5640930919837458, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6909863317325452, total=   3.8s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6733789026417882, total=   5.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5674178056889546, total=   7.6s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6950498707055781, total=   5.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6763347496767043, total=   3.7s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5605836719615811, total=   6.5s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.689878093830809, total=   6.6s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.673194162202106, total=   5.7s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5496859992611748, total=   8.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.689878093830809, total=   6.8s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6962867171623869, total=   5.9s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5607683782785371, total=   2.6s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6826745474695235, total=   6.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.691852946610013, total=   6.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5557813077207241, total=   6.1s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6848910232729959, total=   8.5s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6674672085719564, total=   7.4s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5489471739933506, total=   8.9s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6884004432951607, total=   7.7s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6868649547385923, total=   7.4s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5563354266715922, total=   4.5s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6893239748799409, total=   4.5s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6750415665989286, total=   4.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5596601403768009, total=   4.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6752862947912819, total=   4.1s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6826159246259006, total=   4.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.560398965644625, total=   3.6s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6837827853712597, total=   4.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6896360613338259, total=   4.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5574436645733284, total=   5.4s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6771333579608423, total=   4.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6787363753925735, total=   5.9s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5611377909124492, total=   5.6s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6906169190986332, total=   4.5s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6781821540735267, total=   4.5s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5642777983007019, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7098263760620613, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6944393127655644, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5663095677872183, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7183228666420391, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7047847773877702, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5707425193941633, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7035463612855559, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6929613892481065, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5579977835241965, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7077946065755449, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7036763347496767, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5618766161802734, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6965275212412264, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6898208017735082, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5491318803103066, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6782415958625785, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.673933123960835, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5644625046176579, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6762098263760621, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6604470718640311, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.569634281492427, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6684521610639084, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6864954738592278, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5552271887698559, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6773180642777983, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6610012931830778, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5452530476542298, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6769486516438862, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.687419176057639, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5607683782785371, total=   1.8s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6884004432951607, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6613707740624423, total=   0.6s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5561507203546361, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6869227927595124, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6929613892481065, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5531954192833395, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6904322127816771, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6700535747275078, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5644625046176579, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6970816401920946, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6972104193607981, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5607683782785371, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6830439601034355, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6938850914465177, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5579977835241965, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.726449944588105, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6988730833179383, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5659401551533062, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7257111193202808, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.6944393127655644, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5626154414480975, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.717953454008127, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6909292444116018, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5585519024750647, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7183228666420391, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7040458156290412, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5574436645733284, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7164758034724787, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7014594494734897, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.49556704839305504, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5450683413372738, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5970811010530205, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5079423716291097, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5557813077207241, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5760206909292445, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.4985223494643517, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5868119689693387, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5658599667467209, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5055411895086812, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5960472848171408, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5715869203768705, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5227188769855929, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.6283708902844477, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.619988915573619, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5668636867380864, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.685260435906908, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6898208017735082, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.5681566309567787, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6909863317325452, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6966561980417514, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5611377909124492, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6913557443664573, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6924071679290597, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5432212781677134, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6926486885851496, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.700905228154443, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5685260435906908, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6874769117103805, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6927766488084242, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5640930919837458, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7164758034724787, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6962867171623869, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5615072035463613, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7146287403029183, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7012747090338075, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5522718876985593, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7164758034724787, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6959172362830224, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5615072035463613, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.71315108976727, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7020136707925365, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5611377909124492, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7041004802364241, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7025678921115832, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.513852973771703, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5775766531215367, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5662294476260854, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5169929811599556, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5672330993719985, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5610567153149825, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5166235685260436, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5751754710011082, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5784223166451136, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5302918359807905, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.583302548947174, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5871051173101792, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5339859623199114, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5849649057997783, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5808239423609828, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5491318803103066, total=   0.6s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6865533801256003, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.700905228154443, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5533801256002955, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.699113409678611, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6909292444116018, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5635389730328777, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6974510528260066, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6805837797893959, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5676025120059106, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6885851496121167, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6896360613338259, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5637236793498338, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6926486885851496, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.679105856271938, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5753601773180643, total=   3.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.685075729589952, total=   3.9s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6778126731941622, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5724048762467676, total=   3.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.7149981529368304, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6900055422131904, total=   4.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5670483930550425, total=   5.3s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6832286664203916, total=   5.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6709772769259191, total=   4.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5668636867380864, total=   4.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6895086811968969, total=   3.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.7044152965084057, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5611377909124492, total=   3.6s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.694680458071666, total=   3.9s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6722704600036948, total=   3.9s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.564647210934614, total=   6.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6835980790543037, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6811380011084427, total=   6.6s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5585519024750647, total=   2.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.689878093830809, total=   6.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6846480694624053, total=   5.7s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5579977835241965, total=   6.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6902475064647211, total=   6.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6645113615370405, total=   5.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5567048393055043, total=   6.6s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6885851496121167, total=   6.8s
  ConvergenceWarning)
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6826159246259006, total=   5.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5589213151089767, total=   7.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6961581086073144, total=   6.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.675411047478293, total=   5.9s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5567048393055043, total=   4.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.69449575175471, total=   4.3s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6846480694624053, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5698189878093831, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.680458071666051, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6743026048401995, total=   3.6s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5528260066494274, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6861839674916882, total=   4.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6600775909846666, total=   4.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.574067233099372, total=   1.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6811968969338751, total=   4.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6968409384814336, total=   3.5s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5653860362024381, total=   3.7s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6787957148134466, total=   4.3s
[CV] alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6781821540735267, total=   3.8s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5712966383450314, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7155522718876985, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7003510068353963, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5796084226080532, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7142593276690062, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7029373729909477, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5679719246398227, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7061322497229405, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.6844633290227231, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5764684152198005, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7107499076468415, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6949935340846112, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5609530845954932, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7044698928703361, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.701644189913172, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5570742519394163, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.680458071666051, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6789211158322557, total=   0.3s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.550978943479867, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6787957148134466, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6781821540735267, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5664942741041744, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.6763945326930181, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.6735636430814705, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5624307351311415, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6795345400812708, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6735636430814705, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5520871813816033, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6826745474695235, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6805837797893959, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5546730698189878, total=   0.6s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6856298485408201, total=   1.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.657491224829115, total=   1.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5613224972294052, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6906169190986332, total=   0.2s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6704230556068723, total=   0.4s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5605836719615811, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6793498337643148, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6870496951782745, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5546730698189878, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6863686738086443, total=   0.1s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6837243672639941, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5489471739933506, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6924639822681936, total=   0.0s
[CV] alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6927766488084242, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5524565940155153, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.7042851865533801, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6996120450766673, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5548577761359439, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7162910971555227, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6999815259560318, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5659401551533062, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.7155522718876985, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6985036024385738, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5522718876985593, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7188769855929072, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6922224274893775, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5628001477650536, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7249722940524566, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6996120450766673, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5559660140376801, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6813816032508312, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6737483835211527, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5576283708902845, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.6739933505725896, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.675411047478293, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5522718876985593, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.7005910602142593, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.6837243672639941, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5432212781677134, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.6800886590321389, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.6796600775909847, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5618766161802734, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.6815663095677872, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.6743026048401995, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5498707055781308, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6932028075360177, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6685756512100499, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5552271887698559, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6795345400812708, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6931461296877887, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5720354636128555, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6854451422238641, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6920376870496951, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5605836719615811, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6859992611747322, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6986883428782561, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5736978204654599, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6917251570003694, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6946240532052467, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5511636497968231, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7190616919098634, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6968409384814336, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.5561507203546361, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.7299593646102697, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.7005357472750785, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5559660140376801, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.717584041374215, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.7033068538703122, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.555411895086812, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7210934613963798, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7047847773877702, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5515330624307351, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.7183228666420391, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6988730833179383, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5496859992611748, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.6697451052826007, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.6796600775909847, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5476542297746583, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6791651274473587, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6877886569370035, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5539342445511637, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.6773180642777983, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.6818769628671716, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5561507203546361, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.666420391577392, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.6813227415481249, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5474695234577023, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.6662356852604359, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.678366894513209, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5552271887698559, total=   0.4s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6867380864425563, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6946240532052467, total=   0.3s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5583671961581086, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6928333949021056, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6744873452798817, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5618766161802734, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6786110084964906, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6938850914465177, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.5520871813816033, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.690062800147765, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.691113984851284, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5585519024750647, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.685075729589952, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.7025678921115832, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5642777983007019, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6695603989656447, total=   2.3s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.7053389987068169, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5670483930550425, total=   2.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6579239009974142, total=   2.8s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6338444485497875, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5722201699298116, total=   3.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6638345031400074, total=   2.8s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6286717162386847, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5620613224972294, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6608792020687108, total=   2.7s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6421577683354887, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5631695603989656, total=   2.7s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6651274473586997, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6366155551450212, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5587366087920207, total=   5.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6974510528260066, total=   5.6s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6877886569370035, total=   4.4s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5585519024750647, total=   5.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.699113409678611, total=   4.7s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6779974136338445, total=   4.5s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.550794237162911, total=   4.7s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6828592537864795, total=   4.5s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6894513208941437, total=   4.3s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5589213151089767, total=   4.8s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6819357222016993, total=   4.9s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6809532606687604, total=   4.4s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5576283708902845, total=   4.5s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.7016992981159955, total=   4.4s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6872344356179567, total=   4.3s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5844107868489102, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6821204285186553, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6938850914465177, total=   2.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5698189878093831, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6887698559290728, total=   2.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6951782745242934, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5565201329885482, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6885851496121167, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6828006650655829, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5624307351311415, total=   2.3s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6856298485408201, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6789211158322557, total=   2.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5489471739933506, total=   2.2s
  ConvergenceWarning)
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6885851496121167, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6864954738592278, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5670483930550425, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.717768747691171, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.700166266395714, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5613224972294052, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.717214628740303, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6937003510068354, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5727742888806797, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7046545991872922, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6999815259560318, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5709272257111193, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7146287403029183, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6973951598004803, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5657554488363502, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7113040265977096, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7086643266210974, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5382342076099003, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6922792759512375, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6931461296877887, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5729589951976357, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6882157369782047, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6916682061703306, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5567048393055043, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6865533801256003, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6887123591354147, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5591060214259328, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6876616180273365, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.688897099575097, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5565201329885482, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6920945696342815, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6894513208941437, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5687107499076468, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6887698559290728, total=   0.5s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6824311841862184, total=   1.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5618766161802734, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.7011451791651274, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.7012747090338075, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5576283708902845, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6980051717768748, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6630334380195825, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5478389360916144, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6858145548577761, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.699427304636985, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5711119320280753, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6874769117103805, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6765194901163865, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5613224972294052, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.717214628740303, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6916682061703306, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5594754340598449, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7210934613963798, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.6924071679290597, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5668636867380864, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.7209087550794238, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6700535747275078, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.574251939416328, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7125969708164019, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7036763347496767, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.555411895086812, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7159216845216106, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.702383151671901, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5531954192833395, total=   0.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.6863686738086443, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.6805837797893959, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.550794237162911, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.6859992611747322, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.6809532606687604, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5579977835241965, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.6811968969338751, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.6750415665989286, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5448836350203177, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.6848910232729959, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.676888970995751, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5565201329885482, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.6824898411525674, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.6840938481433586, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5495012929442187, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6932028075360177, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6719009791243303, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.5544883635020318, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6837827853712597, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6894513208941437, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5705578130772072, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6968969338751385, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6885276186957325, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5524565940155153, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6869227927595124, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6887123591354147, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5598448466937569, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6859992611747322, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6785516349528912, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5491318803103066, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7161063908385666, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7142065398115648, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.54617657923901, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7284817140746214, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7060779604655459, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5550424824528999, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7203546361285555, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7029373729909477, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5589213151089767, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7270040635389731, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7066321817845926, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5502401182120429, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7249722940524566, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7086643266210974, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5465459918729221, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.6871074990764684, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.6752263070386108, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5557813077207241, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6736239379386775, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6748568261592462, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5441448097524936, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.6688215736978205, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.6757805283576575, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.560214259327669, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.6686368673808645, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.6818769628671716, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5567048393055043, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.6704839305504249, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.6839091077036763, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5535648319172516, total=   0.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6932028075360177, total=   0.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.692591908368742, total=   0.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5620613224972294, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6837827853712597, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6996120450766673, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5434059844846694, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6920945696342815, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6844633290227231, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5574436645733284, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6972663465090506, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6798448180306669, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5718507572958995, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.698928703361655, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6962867171623869, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5659401551533062, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6588474325821944, total=   2.4s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6510253094402365, total=   2.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5679719246398227, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.652752124122645, total=   2.4s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6362460742656567, total=   2.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5624307351311415, total=   2.5s
  ConvergenceWarning)
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6612486147026229, total=   2.6s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6504710881211897, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5670483930550425, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.7092722571111932, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6319970441529651, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5528260066494274, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6542297746582934, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6552743395529281, total=   2.4s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5755448836350203, total=   5.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6908016254155892, total=   5.7s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6840938481433586, total=   5.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5557813077207241, total=   6.0s
  ConvergenceWarning)
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6856298485408201, total=   5.8s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6877886569370035, total=   7.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5591060214259328, total=   4.8s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6799039527151829, total=   7.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6977646406798448, total=   8.4s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.555411895086812, total=   5.8s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6817510158847433, total=   4.7s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.688158137816368, total=   4.9s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5683413372737348, total=   4.8s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6941263391207979, total=   4.6s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.688158137816368, total=   4.9s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5616919098633173, total=   2.8s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6835980790543037, total=   2.3s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6955477554036579, total=   2.3s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5605836719615811, total=   2.4s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6858145548577761, total=   2.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6750415665989286, total=   2.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5615072035463613, total=   2.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6889545622460288, total=   2.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6807685202290782, total=   2.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5738825267824159, total=   2.4s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6848910232729959, total=   2.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6909292444116018, total=   2.0s
  ConvergenceWarning)
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5677872183228666, total=   1.6s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6885851496121167, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.0001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6785516349528912, total=   2.6s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5711119320280753, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7114887329146656, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6961019767227046, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5766531215367565, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7155522718876985, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7038610751893589, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5746213520502401, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7137052087181381, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7038610751893589, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5718507572958995, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7161063908385666, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6890818400147792, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5733284078315478, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7114887329146656, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6992425641973028, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5596601403768009, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6893239748799409, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6752263070386108, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5544883635020318, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.676025120059106, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6794753371513024, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5446989287033617, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.680273365349095, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.6715314982449658, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5552271887698559, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6808274842999631, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6853870312211343, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5666789804211304, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6913557443664573, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6870496951782745, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.569634281492427, total=   0.5s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6928333949021056, total=   0.8s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6972104193607981, total=   0.9s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5712966383450314, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6859992611747322, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6949935340846112, total=   0.2s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.560029553010713, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.7042851865533801, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.687419176057639, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5725895825637237, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.680642777983007, total=   0.1s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6853870312211343, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5620613224972294, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6981898780938308, total=   0.0s
[CV] alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.0001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.7042305560687234, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5513483561137791, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.717953454008127, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6861259929798633, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5535648319172516, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7216475803472479, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6997967855163495, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5524565940155153, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.7216475803472479, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6946240532052467, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5435906908016254, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7233099371998523, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7064474413449104, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.54617657923901, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7089028444772811, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6868649547385923, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4665681566309568, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4050609530845955, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.48235728801034544, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4754340598448467, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4115256741780569, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.467762793275448, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.47340229035833026, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.4083856667898042, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5353777941991502, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.47617288511267086, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.4078315478389361, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.504526140772215, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.47894347986701147, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.4009974141115626, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.48272676888970995, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5605836719615811, total=   1.6s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6765792390099742, total=   1.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6818769628671716, total=   1.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5583671961581086, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6784263021795346, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6877886569370035, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5537495382342076, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6717768747691171, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6905597635322372, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5557813077207241, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6715921684521611, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.685941252540181, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5304765422977465, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6725157000369413, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6728246813227415, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5214259327669006, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7096416697451052, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6831701459449473, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.523088289619505, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.7144440339859623, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6898208017735082, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5221647580347248, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.7146287403029183, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6833548863846296, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.5271518285925378, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.708348725526413, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6885276186957325, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5221647580347248, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.708348725526413, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6877886569370035, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5007388252678242, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.42944218692279273, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5281729170515426, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5014776505356483, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.42611747321758403, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5207832994642527, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5003694126339121, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.4244551163649797, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.520229078145206, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.504802364240857, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.4268562984854082, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5248475891372621, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5025858884373846, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.42223864056150723, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5298355810086828, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5374953823420761, total=   2.5s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6884004432951607, total=   2.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6646961019767227, total=   2.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5478389360916144, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6815663095677872, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6877886569370035, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.550978943479867, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6834133727373476, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6929613892481065, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.5398965644625047, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6837827853712597, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6957324958433401, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5345400812707795, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6627262652382712, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6706077960465546, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5302918359807905, total=   3.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.661618027336535, total=   4.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6218363199704415, total=   4.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5358330254894718, total=   5.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6608792020687108, total=   4.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6046554590799926, total=   4.6s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5471001108237902, total=   4.5s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6623568526043591, total=   5.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6198041751339368, total=   4.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5299224233468784, total=   5.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6701145179165128, total=  15.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6151856641418807, total=  15.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5448836350203177, total=   5.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6505356483191725, total=   4.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6212820986513948, total=   4.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5567048393055043, total=   7.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.657739194680458, total=   7.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6722704600036948, total=   6.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5312153675655708, total=   6.5s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6547838936091614, total=   7.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.673194162202106, total=   7.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5476542297746583, total=   6.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6643886220908755, total=   6.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6696840938481433, total=   6.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.532877724418175, total=  12.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6645733284078316, total=   8.5s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6595233696656198, total=   6.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5515330624307351, total=   6.7s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6630956778721833, total=   6.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6685756512100499, total=   6.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5452530476542298, total=   4.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6605097894347987, total=   7.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6519490116386477, total=   6.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.54617657923901, total=   7.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6754710011082379, total=   4.1s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6630334380195825, total=   3.6s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5539342445511637, total=   3.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6651274473586997, total=   7.6s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6667282468132274, total=   7.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5432212781677134, total=   5.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6647580347247876, total=   1.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6270090522815445, total=   3.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5439601034355375, total=   4.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.661802733653491, total=   4.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6772584518751155, total=   3.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5598448466937569, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7066863686738086, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6973951598004803, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5441448097524936, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.708348725526413, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6985036024385738, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5624307351311415, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7089028444772811, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6968409384814336, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5572589582563724, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7120428518655338, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.688897099575097, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5528260066494274, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.694680458071666, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6813227415481249, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.49279645363871444, total=   1.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4554857776135944, total=   1.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5496028080546832, total=   0.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.49094939046915403, total=   1.9s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.44975988178795717, total=   0.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5503417698134122, total=   1.6s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.48947173993350573, total=   0.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.46231991134096784, total=   1.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.4919637908738223, total=   0.8s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5040635389730329, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.490764684152198, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5433216331054868, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.4892870336165497, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.528075360177318, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6052096803990393, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5496859992611748, total=   5.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6741780568895456, total=   4.3s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6863107334195455, total=   3.0s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5445142223864056, total=   0.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6558921315108976, total=   1.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6707925364862368, total=   0.7s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5524565940155153, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6824898411525674, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6853870312211343, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5389730328777245, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6682674547469524, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6689451320894144, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.536941263391208, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6691909863317326, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6602623314243488, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5524565940155153, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.7194311045437753, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.7070016626639571, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5537495382342076, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7209087550794238, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7018289303528542, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5570742519394163, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.7212781677133357, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.7055237391464991, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5544883635020318, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7122275581824898, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7101422501385554, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5472848171407462, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7157369782046547, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7005357472750785, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.4756187661618027, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.4142962689323975, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5377794199150194, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.4848540820096047, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.4235315847801995, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.46794753371513026, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.48134466198743997, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.42981159955670484, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5525586550895991, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.48226819357222017, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.42316217214628743, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5008313319785701, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4835611377909125, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4205762837089028, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.46887123591354146, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5393424455116365, total=   1.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6642039157739195, total=   1.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6992425641973028, total=   1.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.54617657923901, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.666420391577392, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.688158137816368, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5411895086811969, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6695603989656447, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.688897099575097, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5511636497968231, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6725157000369413, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6748568261592462, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.541743627632065, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.666605097894348, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.674672085719564, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5330624307351312, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7127816771333579, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6900055422131904, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.532138899150351, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7113040265977096, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.691852946610013, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5339859623199114, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7103804950129294, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6996120450766673, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5306612486147027, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7114887329146656, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.700166266395714, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.531954192833395, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7109346139637975, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7042305560687234, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5116364979682305, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.42981159955670484, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5224459634213929, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5147765053564832, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.4412633912079793, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5224459634213929, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.504432951606945, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.43923162172146285, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.520229078145206, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5155153306243073, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.4364610269671223, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5357472750785147, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5081270779460657, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.4407092722571112, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5423979309070756, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5511636497968231, total=   2.9s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6859992611747322, total=   2.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6961019767227046, total=   2.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5530107129663835, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6741780568895456, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6966561980417514, total=   0.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5524565940155153, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.680458071666051, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6946240532052467, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5452530476542298, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.680273365349095, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6787363753925735, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5495012929442187, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6684521610639084, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6907445039719194, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5352789065386037, total=   5.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6459179903952715, total=   5.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6835396268243118, total=   4.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5362024381233839, total=   4.9s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.657000369412634, total=   4.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6159246259006096, total=   3.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5374953823420761, total=   4.5s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6475803472478758, total=   7.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6534269351561057, total=   6.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.527336534909494, total=   4.5s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6557074251939417, total=   4.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6340291889894698, total=   3.9s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5339859623199114, total=   4.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.657369782046546, total=   3.9s
  ConvergenceWarning)
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6179567707371143, total=   5.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.555596601403768, total=  12.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6717768747691171, total=   7.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6650655828560872, total=   7.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.545991872922054, total=   8.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6678980421130403, total=   7.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6955477554036579, total=   6.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5557813077207241, total=   6.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6551533062430736, total=   6.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6669129872529097, total=   5.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5430365718507573, total=   6.9s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6451791651274473, total=   7.9s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6694993534084611, total=   8.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5411895086811969, total=   7.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6747321758404138, total=  11.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6707925364862368, total=  12.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5585519024750647, total=   4.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6682674547469524, total=   4.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6803990393497137, total=   4.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5581824898411526, total=   4.5s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6690062800147765, total=   5.0s
  ConvergenceWarning)
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6504710881211897, total=   5.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5592907277428888, total=   4.9s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6599556704839306, total=   0.3s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6828006650655829, total=   3.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5354636128555597, total=   3.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6730698189878094, total=   5.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6497321263624607, total=   7.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5478389360916144, total=   6.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6586627262652383, total=   4.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6735636430814705, total=   5.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5618766161802734, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7192463982268194, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7075558839830038, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5539342445511637, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7137052087181381, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6966561980417514, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5559660140376801, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7149981529368304, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.6809532606687604, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5659401551533062, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7068710749907647, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6864954738592278, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5609530845954932, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7188769855929072, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6892665804544614, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4774658293313631, total=   2.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4338751385297377, total=   3.5s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4884537225198596, total=   1.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.4996305873660879, total=   1.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.44384927964536386, total=   1.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5091446517642712, total=   0.9s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.495382342076099, total=   0.5s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.47284817140746216, total=   0.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5050803620912617, total=   0.8s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.4889176209826376, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.4987070557813077, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.531498244965823, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5193941632803842, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5157000369412634, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5109920561610937, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5465459918729221, total=   4.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6741780568895456, total=   3.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6807685202290782, total=   3.4s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5572589582563724, total=   0.6s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6743627632065017, total=   0.7s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6578607057084795, total=   0.5s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5402659770964167, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6645733284078316, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6752263070386108, total=   0.2s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.550978943479867, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6686368673808645, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.650655828560872, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5446989287033617, total=   0.0s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6686368673808645, total=   0.1s
[CV] alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6948087936449289, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5565201329885482, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.7185075729589951, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6948087936449289, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5544883635020318, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.7190616919098634, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6938850914465177, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5559660140376801, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.7190616919098634, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6938850914465177, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5487624676763946, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.7194311045437753, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6898208017735082, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5550424824528999, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.7157369782046547, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.685202290781452, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4637975618766162, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5827484299963058, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.6440051727323111, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4652752124122645, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5821943110454377, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.6425272492148532, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.4689693387513853, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5823790173623938, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.6441899131719934, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.46970816401920945, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5783154783893609, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.647699981525956, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.46823051348356115, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5821943110454377, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.6425272492148532, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5546730698189878, total=   0.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6834133727373476, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6829854055052651, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5450683413372738, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6832286664203916, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6639571402179937, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5480236424085704, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6800886590321389, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6826159246259006, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5511636497968231, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6584780199482823, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.691113984851284, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5421130402659771, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6762098263760621, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6844633290227231, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5221647580347248, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.7166605097894349, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6800295584703492, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.5157000369412634, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.7135205024011821, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6805837797893959, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5120059106021426, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.71315108976727, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6798448180306669, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.5336165496859993, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.7146287403029183, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.676888970995751, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5258588843738455, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.708718138160325, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6892665804544614, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.467676394532693, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5980790543036572, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.6377239977831147, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.45844107868489103, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6230144070927226, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6283022353593202, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.467491688215737, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5677872183228666, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.6284869757990024, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.4680458071666051, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5803472478758773, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.6323665250323296, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.46878463243442925, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5736978204654599, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.6323665250323296, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5565201329885482, total=   1.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6832286664203916, total=   1.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6818769628671716, total=   1.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5517177687476912, total=   0.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.69449575175471, total=   0.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6975799002401626, total=   0.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5437753971185815, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6865533801256003, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6929613892481065, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.5557813077207241, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6791651274473587, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.676888970995751, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5446989287033617, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6786110084964906, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6700535747275078, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.504802364240857, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6187661618027337, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5804544614816183, total=   4.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5116364979682305, total=   4.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6115626154414481, total=   4.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5795307592832071, total=   2.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5079423716291097, total=   2.7s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6102696712227558, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5926473305006466, total=   2.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5096047284817141, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6087920206871075, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5806392019213006, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5132988548208349, total=   6.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6213520502401182, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5765749122482912, total=   4.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5402659770964167, total=   8.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6717768747691171, total=   6.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6772584518751155, total=   4.9s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5541189508681197, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6701145179165128, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6525032329576944, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5587366087920207, total=   4.9s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6608792020687108, total=   1.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6519490116386477, total=   4.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5493165866272627, total=   4.7s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.657554488363502, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6639571402179937, total=   4.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5471001108237902, total=   4.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6621721462874031, total=   6.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.671716238684648, total=   8.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5520871813816033, total=   3.9s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6682674547469524, total=   3.9s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6733789026417882, total=   3.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5465459918729221, total=   3.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6736239379386775, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6702383151671901, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5574436645733284, total=   2.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6564462504617657, total=   2.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.658969148346573, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5544883635020318, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6741780568895456, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6687603916497321, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5498707055781308, total=   2.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6669745105282601, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.673194162202106, total=   2.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5548577761359439, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7277428888067972, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7012747090338075, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5491318803103066, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7290358330254895, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7095880288195086, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5530107129663835, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7273734761728851, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7064474413449104, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5613224972294052, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7214628740302919, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7029373729909477, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.555411895086812, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7253417066863687, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6979493811195271, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5120059106021426, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6230144070927226, total=   0.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6471457602069093, total=   0.8s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5107129663834503, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6311414850387883, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.663402918898947, total=   1.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5051717768747691, total=   0.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.639083856667898, total=   0.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6600775909846666, total=   0.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5145917990395271, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6494274104174362, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6525032329576944, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5277059475434059, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6352050240118212, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6443746536116756, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5491318803103066, total=   1.6s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6810121906169191, total=   2.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6757805283576575, total=   1.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5293683043960103, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6765792390099742, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6802142989100314, total=   0.4s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5591060214259328, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6680827484299963, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.661924995381489, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.541558921315109, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6727004063538973, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6321817845926473, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5432212781677134, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6654968599926118, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6850175503417698, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5541189508681197, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.7148134466198744, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.7014594494734897, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5543036571850757, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7164758034724787, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.7020136707925365, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5568895456224603, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.717768747691171, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.7038610751893589, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5502401182120429, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7148134466198744, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.7053389987068169, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5482083487255264, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7155522718876985, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.7029373729909477, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.4667528629479128, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.610823790173624, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5758359504895622, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.47303287772441815, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5844107868489102, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.6486236837243673, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.46416697451052824, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5805319541928334, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5896914834657306, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.4684152198005172, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.6165496859992612, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5786070570847959, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.47487994089397856, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.6141485038788327, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.6591538887862554, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5373106760251201, total=   0.9s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6887698559290728, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6850175503417698, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.5565201329885482, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6547838936091614, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.685941252540181, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5517177687476912, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6828592537864795, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6957324958433401, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5524565940155153, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6699298115995567, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6807685202290782, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5537495382342076, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6630956778721833, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6778126731941622, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5286294791281861, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.7072404876246767, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6957324958433401, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5295530107129663, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.7063169560398965, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6996120450766673, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5336165496859993, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.7094569634281492, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6789211158322557, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5157000369412634, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.7114887329146656, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.6658045446148162, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5299224233468784, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7096416697451052, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.7036763347496767, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.4549316586627263, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5725895825637237, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.6310733419545539, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.4671222755818249, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6213520502401182, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.6414188065767596, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.46361285555966014, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5869966752862948, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5327914280435987, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.4567787218322867, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5858884373845585, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.6307038610751894, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.46786110084964905, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5718507572958995, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.6312580823942361, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.555411895086812, total=   1.9s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6920945696342815, total=   3.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6883428782560502, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5489471739933506, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.689693387513853, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6997967855163495, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5487624676763946, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6861839674916882, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6840938481433586, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5528260066494274, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6887698559290728, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.7077406244226861, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.532877724418175, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6754710011082379, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6706077960465546, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.504432951606945, total=   4.4s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6074990764684152, total=   4.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5867356364308147, total=   3.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.504432951606945, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6171038049501293, total=   2.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5956031775355626, total=   2.8s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5131141485038788, total=   2.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6117473217584042, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5771291335673379, total=   2.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5090506095308459, total=   2.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6115626154414481, total=   2.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6284869757990024, total=   3.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5088659032138899, total=   2.4s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6093461396379756, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5898762239054129, total=   2.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5374953823420761, total=   4.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6690062800147765, total=   8.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6876039164973212, total=   8.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5446989287033617, total=   8.9s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6682674547469524, total=   6.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6890818400147792, total=   4.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5378647949759882, total=   5.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.657000369412634, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.676888970995751, total=   4.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5448836350203177, total=   4.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6649427410417437, total=   5.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6576759652687973, total=   4.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5450683413372738, total=   4.9s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6738086442556336, total=   7.4s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6798448180306669, total=   4.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5664942741041744, total=   2.9s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6747321758404138, total=   2.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6630334380195825, total=   2.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5594754340598449, total=   2.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6630956778721833, total=   3.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.676888970995751, total=   2.3s
  ConvergenceWarning)
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5336165496859993, total=   2.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6568156630956778, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6743026048401995, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5496859992611748, total=   2.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6867380864425563, total=   3.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6532421947164234, total=   3.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5317694865164388, total=   2.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6699298115995567, total=   2.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.001, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6722704600036948, total=   2.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5581824898411526, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7188769855929072, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7018289303528542, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5528260066494274, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7258958256372368, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7142065398115648, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.550978943479867, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7190616919098634, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7094032883798264, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5672330993719985, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7279275951237533, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7090338075004619, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5585519024750647, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.717768747691171, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7062627009052281, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5103435537495382, total=   1.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6459179903952715, total=   1.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6680214298910031, total=   0.9s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5236424085703731, total=   1.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6457332840783154, total=   1.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6635876593386292, total=   2.3s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5169929811599556, total=   0.5s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.6449944588104913, total=   0.4s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.658230186587844, total=   0.6s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5153306243073513, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.661802733653491, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6549048586735636, total=   0.2s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.495382342076099, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6510897672700406, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.6550895991132459, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5448836350203177, total=   1.8s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6747321758404138, total=   1.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6611860336227601, total=   1.4s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5543036571850757, total=   0.7s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6782415958625785, total=   0.4s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6774431923147977, total=   0.3s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5434059844846694, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6693756926486886, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6872344356179567, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5476542297746583, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6693756926486886, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6840938481433586, total=   0.1s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5653860362024381, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6422238640561507, total=   0.0s
[CV] alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.001, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6844633290227231, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.48005171776874767, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6871074990764684, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6489931646037318, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.4778352419652752, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6649427410417437, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6720857195640125, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.4774658293313631, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6861839674916882, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6423425087751709, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.4802364240857037, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.661802733653491, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6816922224274894, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.47857406723309937, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6859992611747322, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6587844079068909, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4665681566309568, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4102327299593646, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.428043598743765, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.47986701145179167, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4130033247137052, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.42582671346757806, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.47765053564831916, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.3939785740672331, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.427304636985036, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.4689693387513853, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.40062800147765054, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.44134491040088675, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.48817879571481343, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.4144809752493535, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.4372806207278773, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5432212781677134, total=   4.0s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.69449575175471, total=   3.8s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6890818400147792, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5363871444403399, total=   1.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6795345400812708, total=   1.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6798448180306669, total=   1.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.532138899150351, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6649427410417437, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6691298725290966, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.528075360177318, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6693756926486886, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.664880842416405, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5077576653121537, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6566309567787219, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6792905967116202, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.4841152567417806, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6856298485408201, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6573064843894328, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.4837458441078685, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6885851496121167, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6452983558100869, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.4820834872552641, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6837827853712597, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6452983558100869, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.47949759881787957, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6813816032508312, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6434509514132644, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.48005171776874767, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6863686738086443, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6597081101053021, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5199482822312523, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.4560398965644625, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.4322926288564567, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5175471001108238, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.4328468501755034, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5129294421869228, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.47155522718876985, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.4090153334564936, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5168082748429996, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.46601403768008864, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.41714391280251245, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5182859253786479, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.44791281861839677, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.4293367818215407, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5398965644625047, total=   4.8s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6771333579608423, total=   7.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.664880842416405, total=   8.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.5277059475434059, total=   1.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.685075729589952, total=   1.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6652503232957695, total=   1.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5249353527890653, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6751015884743258, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6711620173656013, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.513852973771703, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6545991872922053, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6373545169037502, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5193941632803842, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6512744735869966, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6794753371513024, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5127447358699667, total=   7.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5182859253786479, total=   4.8s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5416589691483465, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.4944588104913188, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6211673439231622, total=   4.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5987437650101607, total=   4.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5108976727004063, total=   4.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5816401920945696, total=   4.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5786070570847959, total=   4.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5123753232360547, total=   4.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5129294421869228, total=   4.7s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.545723258821356, total=   4.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.504802364240857, total=   6.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5254894717399335, total=   5.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5468317014594495, total=   5.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5332471370520872, total=   7.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6339120797931289, total=   6.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6501016072418252, total=   6.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5441448097524936, total=   7.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6461026967122275, total=   7.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6757805283576575, total=   6.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5181012190616919, total=   6.7s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6510897672700406, total=   7.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6403103639386661, total=   6.0s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5238271148873291, total=   6.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6424085703731067, total=   6.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6502863476815075, total=   6.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5317694865164388, total=   6.9s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6189508681196897, total=   6.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.649916866802143, total=   6.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5397118581455486, total=   4.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6440709272257111, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6473305006465916, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5467306981898781, total=   3.7s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6285555966014038, total=   3.8s
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6443746536116756, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5454377539711858, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6429626893239749, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.649916866802143, total=   3.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.523272995936461, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6383450314000739, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6565675226307038, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5306612486147027, total=   4.5s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.629479128186184, total=   4.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.647699981525956, total=   3.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5216106390838566, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7096416697451052, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6811380011084427, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5208718138160325, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.712966383450314, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.685941252540181, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5236424085703731, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7098263760620613, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6798448180306669, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5214259327669006, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7089028444772811, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6864954738592278, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5295530107129663, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.7066863686738086, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6818769628671716, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5332471370520872, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4124492057628371, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.43044522445963423, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5312153675655708, total=   0.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.4190986331732545, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.43801958248660633, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5306612486147027, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.421130402659771, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5510807315721411, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5437753971185815, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.4266715921684522, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.4832809902087567, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5192094569634281, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.4268562984854082, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.44540920007389617, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5203176948651644, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6627262652382712, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6682061703306854, total=   3.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5354636128555597, total=   1.7s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6675286294791282, total=   1.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6691298725290966, total=   1.2s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5371259697081641, total=   0.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.657739194680458, total=   0.4s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6687603916497321, total=   0.3s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5472848171407462, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6612486147026229, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6778126731941622, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5214259327669006, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.657739194680458, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6595233696656198, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.46878463243442925, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6701145179165128, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6157398854609274, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.4695234577022534, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.662541558921315, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.6142619619434694, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.46823051348356115, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6782415958625785, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6174025494180676, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.46915404506834135, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.6686368673808645, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.6179567707371143, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.46786110084964905, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.6823051348356114, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.607980786994273, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.4865164388622091, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.47487994089397856, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.38869388509144653, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.48817879571481343, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.43535278906538605, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.41825235544060596, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.4844846693756926, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.46084226080531954, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.4232403473120266, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.4796823051348356, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.4726634650905061, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.44725660447071863, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5131141485038788, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4205762837089028, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4625900609643451, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5267824159586257, total=   3.8s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6776874769117104, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6907445039719194, total=   4.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.5376800886590322, total=   1.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6634650905060953, total=   1.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6763347496767043, total=   1.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5217953454008127, total=   0.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6610639083856668, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6796600775909847, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.523272995936461, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6680827484299963, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6550895991132459, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5162541558921315, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.657554488363502, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6704230556068723, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.47432582194311046, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6654968599926118, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6225752817291705, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.4746952345770225, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6592168452161064, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6225752817291705, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.47617288511267086, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.676025120059106, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6227600221688527, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.4783893609161433, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.6745474695234577, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.6138924810641049, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.47395640930919836, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.6708533431843369, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.6186957324958433, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5114517916512745, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.4117103804950129, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.4590799926103824, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5105282600664943, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.4689693387513853, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.4594494734897469, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5132988548208349, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.4148503878832656, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.44965823018658785, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5112670853343184, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.46231991134096784, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.4491040088675411, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5267824159586257, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.47118581455485775, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.46480694624053204, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5310306612486148, total=   5.2s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6847063169560399, total=   5.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6909292444116018, total=   5.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5101588474325822, total=   0.8s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6743627632065017, total=   0.9s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6789211158322557, total=   0.8s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5254894717399335, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6769486516438862, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6639571402179937, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5190247506464721, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6518285925378648, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6467762793275448, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5168082748429996, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6520132988548208, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6262700905228155, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5118212042851865, total=   4.4s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6004802364240857, total=   4.4s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5503417698134122, total=   4.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.513852973771703, total=   4.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.514222386405615, total=   4.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5828560871974875, total=   4.8s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5132988548208349, total=   4.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5990025858884374, total=   4.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5893220025863661, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.509235315847802, total=   4.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5766531215367565, total=   4.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6209126177720303, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.48817879571481343, total=   4.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6038049501292945, total=   3.7s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6085350083133197, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5238271148873291, total=   6.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6231991134096786, total=   6.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6216515795307593, total=   5.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5330624307351312, total=  10.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6324344292574806, total=  11.8s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6563827821910216, total=   7.4s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.509420022164758, total=   6.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6492427041004802, total=   6.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6550895991132459, total=   5.7s
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5258588843738455, total=   6.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6352050240118212, total=   5.9s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6205431368926658, total=   6.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.532877724418175, total=   6.7s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6509050609530846, total=   6.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6622944762608535, total=   6.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5391577391946805, total=   3.7s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6464721093461396, total=   3.9s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6443746536116756, total=   3.4s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5397118581455486, total=   3.4s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6385297377170299, total=   3.5s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6502863476815075, total=   3.7s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5155153306243073, total=   3.8s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6366826745474695, total=   3.7s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6225752817291705, total=   3.8s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5129294421869228, total=   3.8s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6557074251939417, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6539811564751524, total=   3.5s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5286294791281861, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6379756187661618, total=   4.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6434509514132644, total=   6.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5299224233468784, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7113040265977096, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6778126731941622, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5308459549316586, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7122275581824898, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7031221134306299, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.532323605467307, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7118581455485777, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.699427304636985, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5291835980790544, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7070557813077207, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6842785885830408, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5286294791281861, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7074251939416328, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6781821540735267, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5339859623199114, total=   0.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4185445142223864, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4697949381119527, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5339859623199114, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.43830809013668265, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5335303898023277, total=   0.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5271518285925378, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.43442925748060585, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.42582671346757806, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5304765422977465, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.43350572589582564, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.4385738038056531, total=   0.0s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5336165496859993, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.4384927964536387, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5250323295769443, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5354636128555597, total=   4.7s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6776874769117104, total=   3.7s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6730094217624238, total=   6.5s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5434059844846694, total=   2.3s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6608792020687108, total=   3.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6722704600036948, total=   3.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5356483191725157, total=   0.5s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6544144809752493, total=   0.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6600775909846666, total=   0.6s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.527890653860362, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.657000369412634, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6665435063735452, total=   0.2s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5380495012929443, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6394532693018101, total=   0.1s
[CV] alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6560133013116571, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.47709641669745106, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6871074990764684, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6456678366894513, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.4778352419652752, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6884004432951607, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6404951043783484, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.47672700406353896, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6813816032508312, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6691298725290966, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.48134466198743997, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6882157369782047, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6597081101053021, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.48042113040265977, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6863686738086443, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6486236837243673, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4647210934613964, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5530107129663835, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5968963606133383, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4647210934613964, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5371259697081641, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5968963606133383, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.4647210934613964, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5408200960472849, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5968963606133383, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.4647210934613964, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5408200960472849, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5968963606133383, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.43405984484669374, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5371259697081641, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5968963606133383, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.5465459918729221, total=   4.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6608792020687108, total=   4.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6652503232957695, total=   2.6s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.5443295160694496, total=   0.5s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6743627632065017, total=   1.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6853870312211343, total=   1.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.5437753971185815, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6706686368673809, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6449288749307224, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.5289988917620982, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6671592168452161, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6824311841862184, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5164388622090875, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6551533062430736, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6621097358211713, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.48042113040265977, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6824898411525674, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6416035470164418, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.48134466198743997, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6908016254155892, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6637723997783115, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.47709641669745106, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6832286664203916, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6561980417513393, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.4842999630587366, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6876616180273365, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.658969148346573, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.4806058367196158, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6935722201699298, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6270090522815445, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.6039164973212636, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.6039164973212636, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5968963606133383, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.5293683043960103, total=   4.5s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6780568895456225, total=   3.8s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6831701459449473, total=   3.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.532693018101219, total=   1.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6736239379386775, total=   1.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6794753371513024, total=   0.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5236424085703731, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6608792020687108, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6798448180306669, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.5038788326560768, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6658662726265239, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6645113615370405, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5072035463612855, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6701145179165128, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6682061703306854, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.4833764314739564, total=   3.1s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5775766531215367, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5693700351006835, total=   3.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5086811968969339, total=   3.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5777613594384928, total=   2.3s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5394420838721596, total=   4.6s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5127447358699667, total=   6.5s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.579054303657185, total=   6.7s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5734343247736929, total=   6.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5079423716291097, total=   7.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5127447358699667, total=   6.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5392573434324773, total=   6.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5103435537495382, total=   7.6s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5783154783893609, total=   8.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5392573434324773, total=   6.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5362024381233839, total=  13.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.634281492427041, total=   9.6s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6347681507481988, total=   4.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5295530107129663, total=   4.7s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6425932766900628, total=   4.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6495473859227785, total=   4.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5362024381233839, total=   4.1s
  ConvergenceWarning)
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6300332471370521, total=   5.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.650655828560872, total=   5.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5398965644625047, total=   4.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.634281492427041, total=   5.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6443746536116756, total=   4.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5360177318064278, total=   5.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6364979682305135, total=   5.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6399408830593016, total=   4.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.541374214998153, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6479497598817879, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6571217439497506, total=   2.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5422977465829332, total=   2.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6401920945696343, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6539811564751524, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5243812338381972, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6416697451052826, total=   2.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6585996674672085, total=   2.5s
  ConvergenceWarning)
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5410048023642409, total=   2.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6246767639453269, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6423425087751709, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5406353897303288, total=   2.4s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6486885851496121, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6423425087751709, total=   2.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5269671222755818, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7140746213520502, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6890818400147792, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.5195788695973402, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7113040265977096, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6792905967116202, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.5164388622090875, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.7138899150350942, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6877886569370035, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.5339859623199114, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.7007757665312153, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6809532606687604, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.5247506464721093, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.712966383450314, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6826159246259006, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.467676394532693, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5546730698189878, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6190652133752078, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.46878463243442925, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5738825267824159, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6209126177720303, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.4665681566309568, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6032508311784263, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.6205431368926658, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.462874030291836, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5777613594384928, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.6198041751339368, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.47247875877355006, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5779460657554488, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.6153704045815629, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5432212781677134, total=   2.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6738086442556336, total=   2.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6656198041751339, total=   2.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5391577391946805, total=   1.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6629109715552272, total=   0.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6597081101053021, total=   0.9s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5493165866272627, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6745474695234577, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6715314982449658, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5308459549316586, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6592168452161064, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6737483835211527, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5192094569634281, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6582933136313261, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6696840938481433, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.46915404506834135, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6608792020687108, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.6168483280990209, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.47007757665312155, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.661987439970447, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.6013301311657122, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.4693387513852974, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6688215736978205, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.6041012377609458, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.46823051348356115, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.6765792390099742, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.6203583964529835, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.467491688215737, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.6773180642777983, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.6103824127101423, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.46453638714444034, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5398965644625047, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.46453638714444034, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5362024381233839, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5375946794753371, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.46453638714444034, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5400812707794607, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5374099390356549, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.46453638714444034, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5398965644625047, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5379641603547016, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4939046915404507, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5398965644625047, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5383336412340661, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.5441448097524936, total=   2.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6778721832286664, total=   2.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6670977276925919, total=   1.9s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.536756557074252, total=   0.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6579239009974142, total=   0.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6842785885830408, total=   0.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5482083487255264, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6640192094569635, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6803990393497137, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.5227188769855929, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6747321758404138, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6796600775909847, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5162541558921315, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6501662356852604, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6650655828560872, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.47395640930919836, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6492427041004802, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.6157398854609274, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.4741411156261544, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6771333579608423, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.6150009237021984, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.4765422977465829, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6634650905060953, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.6231295030482172, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.48079054303657187, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.6867380864425563, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.6175872898577499, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.4774658293313631, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.6667898042113041, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.6410493256973951, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.43405984484669374, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5362024381233839, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.43405984484669374, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5362024381233839, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.43405984484669374, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5362024381233839, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.43405984484669374, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5362024381233839, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.43405984484669374, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5362024381233839, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5387883265607684, total=   3.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6856298485408201, total=   3.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6861259929798633, total=   3.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.5299224233468784, total=   0.7s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6823051348356114, total=   0.7s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6824311841862184, total=   0.7s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5282600664942741, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.689878093830809, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6639571402179937, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.5267824159586257, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.657369782046546, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6670977276925919, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5173623937938677, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6466568156630956, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6652503232957695, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5096047284817141, total=   3.8s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5755448836350203, total=   3.9s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5388878625531128, total=   2.8s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5108976727004063, total=   2.7s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5114517916512745, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.5394420838721596, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.48134466198743997, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5108976727004063, total=   2.6s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5390726029927951, total=   2.2s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5103435537495382, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5759142962689324, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.5387031221134306, total=   2.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5099741411156261, total=   2.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5764684152198005, total=   2.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5401810456308886, total=   2.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5236424085703731, total=   4.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6473956409309198, total=   4.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.6750415665989286, total=   4.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5247506464721093, total=   4.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6557074251939417, total=   4.6s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.6430814705338999, total=   4.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5247506464721093, total=   4.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.6420391577391947, total=   4.5s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.608719748753002, total=   5.7s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5378647949759882, total=   5.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.6586627262652383, total=   4.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.622944762608535, total=   4.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5339859623199114, total=   4.3s
  ConvergenceWarning)
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6257850018470632, total=   4.6s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.6561980417513393, total=   4.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5297377170299225, total=   2.9s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6533062430735131, total=   2.6s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6473305006465916, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5288141854451422, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6355744366457333, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.649916866802143, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.532138899150351, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.643516808274843, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6458525771291336, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5384189139268563, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6503509420022164, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6515795307592832, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5336165496859993, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6254155892131511, total=   2.4s
[CV] alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6471457602069093, total=   2.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.5282600664942741, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.7090875507942371, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6962867171623869, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.532323605467307, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.7090875507942371, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6966561980417514, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5338012560029552, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.7046545991872922, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.68668021429891, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5295530107129663, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7124122644994458, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.7086643266210974, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5282600664942741, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.7127816771333579, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6792905967116202, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4693387513852974, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.6124861470262283, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.620727877332348, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.4713705208718138, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.6148873291466568, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5076667282468132, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.46878463243442925, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5581824898411526, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5141326436356919, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.46693756926486885, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.6126708533431844, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5444300757435803, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.46878463243442925, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5731437015145918, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.541289488268982, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5491318803103066, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.657739194680458, total=   2.6s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6606318123037133, total=   2.5s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5421130402659771, total=   1.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6673439231621722, total=   1.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6778126731941622, total=   0.9s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5533801256002955, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6553380125600295, total=   0.2s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6691298725290966, total=   0.3s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5471001108237902, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6605097894347987, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6502863476815075, total=   0.1s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.541374214998153, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6516438862209087, total=   0.0s
[CV] alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.01, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6606318123037133, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.4569634281492427, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.6278167713335796, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5605024939959357, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.4577022534170669, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.6346509050609531, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5340846111213745, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.4564093091983746, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6634650905060953, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5671531498244966, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.44181751015884746, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5888437384558551, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5196748568261592, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.44144809752493536, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.6562615441448097, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5222612229817107, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5456224602881419, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.3618396749168822, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.48475891372621466, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.54617657923901, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.351865533801256, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4363569185294661, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5445142223864056, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.38031030661248616, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.4359874376501016, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5422977465829332, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.3598079054303657, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.4298910031405875, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5485777613594385, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.39453269301810123, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.4291520413818585, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.48614702622829703, total=   4.6s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.661618027336535, total=   4.2s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.657491224829115, total=   3.9s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.4841152567417806, total=   0.7s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6658662726265239, total=   0.9s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.6462220580084981, total=   0.9s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.48005171776874767, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6392685629848541, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6438204322926289, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.467676394532693, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6326191355744366, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6430814705338999, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.4915035094200222, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5943849279645363, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5856271937927212, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.46324344292574804, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6765792390099742, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5715869203768705, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.4578869597340229, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6653121536756557, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.55920931091816, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.4545622460288142, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6762098263760621, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5617956770737115, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.4772811230144071, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6667898042113041, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6041012377609458, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.4601034355374954, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6739933505725896, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.5638278219102162, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5496859992611748, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.35925378647949757, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.4666543506373545, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5217953454008127, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.40820096047284815, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.42878256050249397, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5241965275212412, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.35260435906908016, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.43469425457232586, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.532508311784263, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.3937938677502771, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.4553851838167375, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5286294791281861, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.3411525674178057, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.467762793275448, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.48189878093830807, total=   3.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6538603620243812, total=   3.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6543506373545169, total=   3.2s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.49741411156261545, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6534909493904691, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.6419730278958063, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.4661987439970447, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6353897303287772, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6353223720672455, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.4830070188400443, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6287403029183598, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6401256234989839, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.49187292205393424, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6270779460657554, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.637169776464068, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.47617288511267086, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6848910232729959, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6188804729355256, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.4671222755818249, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6832286664203916, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6489931646037318, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.4889176209826376, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6244920576283709, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6231295030482172, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.48005171776874767, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.671407462135205, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6423425087751709, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.47801994828223127, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6745474695234577, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6382782191021614, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.541558921315109, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.4667528629479128, total=   6.7s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.42711989654535376, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5563354266715922, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.32397487994089397, total=   0.7s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.37317568815813784, total=   6.7s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5583671961581086, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.4190986331732545, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.4387585442453353, total=   1.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.560029553010713, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.3862209087550794, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.44060594864215774, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5550424824528999, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.45511636497968233, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.427304636985036, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5088659032138899, total=   4.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.629848540820096, total=   3.8s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6578607057084795, total=   3.6s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5210565201329885, total=   3.8s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6398226819357222, total=   3.5s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6297801588767781, total=   4.4s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.500184706316956, total=   1.5s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6377909124492057, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6077960465545909, total=   4.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5216106390838566, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6333579608422608, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6353223720672455, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.4985223494643517, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6280014776505356, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.598928505449843, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.4842999630587366, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6727004063538973, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6613707740624423, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.4896564462504618, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.675655707425194, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6353223720672455, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.4796823051348356, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.671222755818249, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6467762793275448, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.48799408939785743, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6800886590321389, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6423425087751709, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.4826376062061323, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6865533801256003, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6816922224274894, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5579977835241965, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4226080531954193, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.429521522261223, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5587366087920207, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.3374584410786849, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.3541474228708664, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5583671961581086, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.4117103804950129, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.42675041566598926, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5583671961581086, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.3956409309198375, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.42453353038980235, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5574436645733284, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.412079793128925, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.42250138555329764, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5332471370520872, total=   4.6s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6765792390099742, total=   4.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6663587659338629, total=   4.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.5214259327669006, total=   1.6s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6763945326930181, total=   1.6s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6430814705338999, total=   1.9s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.51865533801256, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6540450683413372, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6802142989100314, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.49501292944218694, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6272626523827115, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6545353777941991, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5083117842630218, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.625230882896195, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.663402918898947, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5360177318064278, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5552271887698559, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5743580269721041, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5419283339490211, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5653860362024381, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5507112506927766, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5422977465829332, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5515330624307351, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5512654720118234, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5426671592168452, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5690801625415589, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5553297616848328, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.4865164388622091, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5633542667159217, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5675226307038611, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.439785740672331, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.4436645733284078, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.4901163864769998, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.44809752493535276, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.46416697451052824, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.45298355810086827, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.4421869227927595, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.4501292944218692, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.48512839460557916, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.44846693756926487, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.40709272257111195, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.49658230186587843, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4473586996675286, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4510528260066494, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.4921485313135045, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.4772811230144071, total=   4.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6597709641669746, total=   4.4s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6029927951228524, total=   4.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.5036941263391208, total=   0.8s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6466568156630956, total=   0.9s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6157398854609274, total=   0.9s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.486331732545253, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6693756926486886, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.5883983003879549, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.4857776135943849, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6311414850387883, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.612414557546647, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.49649057997783524, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6025120059106022, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.571217439497506, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5435906908016254, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5805319541928334, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5678921115832256, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5439601034355375, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5633542667159217, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5771291335673379, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5424824528998892, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5866272626523827, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5747275078514686, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.541743627632065, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5851496121167344, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5678921115832256, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5400812707794607, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5683413372737348, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5771291335673379, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.449205762837089, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.444403398596232, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.4862368372436726, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.449205762837089, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.4530845954931659, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.4862368372436726, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.43997044698928706, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.4554857776135944, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.4945501570293737, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.4506834133727374, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.4610269671222756, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.480509883613523, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.4421869227927595, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.40893978574067236, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.48475891372621466, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.47709641669745106, total=   3.4s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6638345031400074, total=   3.5s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6157398854609274, total=   3.3s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.4926117473217584, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.648503878832656, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6118603362276003, total=   0.5s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.4957517547100111, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6313261913557444, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6137077406244227, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.4874399704469893, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6038049501292945, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6005911694069832, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5099741411156261, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6333579608422608, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.5904304452244596, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.4717399335057259, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6660509789434799, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.5699242564197303, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.48947173993350573, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6270779460657554, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6074265656752263, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.476911710380495, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6499815293683044, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6146314428228339, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.4735869966752863, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.662541558921315, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6074265656752263, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.490579977835242, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6346509050609531, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.5736190652133752, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5472848171407462, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5371259697081641, total=   7.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.4773692961389248, total=   6.9s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5454377539711858, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.41004802364240855, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.4853131350452614, total=   7.6s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5541189508681197, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.34743258219431106, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.42582671346757806, total=   1.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5504248245289989, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.4338751385297377, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.47755403657860707, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5522718876985593, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.44569634281492426, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.4762608535008313, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5216106390838566, total=   4.3s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6206132249722941, total=   4.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6186957324958433, total=   4.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5219800517177687, total=   4.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6503509420022164, total=   4.5s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6464067984481803, total=   4.5s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.5101588474325822, total=   0.4s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6304026597709642, total=   0.7s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6118603362276003, total=   3.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5114517916512745, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6326191355744366, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6462220580084981, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5079423716291097, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6182120428518655, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.61019767227046, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.4713705208718138, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.643516808274843, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.570478477738777, total=   0.2s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.47340229035833026, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6461026967122275, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6144467023831517, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.47210934613963795, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.6682674547469524, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.6172178089783854, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.4689693387513853, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6542297746582934, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6129687788656937, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.4746952345770225, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.671222755818249, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5678921115832256, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5515330624307351, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.425748060583672, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.42748937742471826, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.545991872922054, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.42833394902105654, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.4481803066691299, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5543036571850757, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.4277798300701884, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.48106410493256974, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5458071666050979, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.4235315847801995, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.47755403657860707, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5495012929442187, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.40118212042851864, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.4540920007389618, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.528075360177318, total=   4.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6677133357960843, total=   3.9s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6748568261592462, total=   3.7s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5223494643516808, total=   1.6s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.652382711488733, total=   1.7s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6630334380195825, total=   1.7s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.5072035463612855, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6656815663095678, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6639571402179937, total=   0.3s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5171776874769117, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.625230882896195, total=   0.1s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6316275632736006, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5086811968969339, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6346509050609531, total=   0.0s
[CV] alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=True, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6024385738038056, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.4554857776135944, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5916143332101957, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=1e-05, score=0.5287271383705893, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.4558551902475065, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.615626154414481, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.0001, score=0.5765749122482912, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.439785740672331, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.6405615072035463, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.001, score=0.5721411416959172, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.4521610639083857, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.6134096786110085, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.01, score=0.5625346388324404, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.43904691540450685, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5831178426302179, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l2, tol=0.1, score=0.5752817291705155, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=1e-05, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.0001, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.001, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.01, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=l1, tol=0.1, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.4896564462504618, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6675286294791282, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=1e-05, score=0.6549048586735636, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.4817140746213521, total=   0.4s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.657554488363502, total=   0.5s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.0001, score=0.662663957140218, total=   0.5s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.4854082009604728, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6446250461765792, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.001, score=0.6216515795307593, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.47210934613963795, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6200591060214259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.01, score=0.6696840938481433, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.5016623568526044, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.625046176579239, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=hinge, penalty=none, tol=0.1, score=0.6081655274339552, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.46638345031400075, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.6682674547469524, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=1e-05, score=0.5701089968594125, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.472294052456594, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.6091614333210196, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.0001, score=0.5726953630149639, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.45899519763575913, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.6780568895456225, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.001, score=0.5773138740070202, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.47063169560398965, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.6791651274473587, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.01, score=0.5673378902641788, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.4595493165866273, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.6505356483191725, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l2, tol=0.1, score=0.592277849621282, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=1e-05, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.0001, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.001, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.01, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.48005171776874767, total=   1.8s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.67584041374215, total=   1.8s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=1e-05, score=0.6624792167005358, total=   2.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.4826376062061323, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.652382711488733, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.0001, score=0.651394790319601, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.5005541189508681, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6448097524935352, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.001, score=0.6584149270275264, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.481529368304396, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6461026967122275, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.01, score=0.6362460742656567, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.5024011821204285, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6414850387883265, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=log, penalty=none, tol=0.1, score=0.6218363199704415, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.49371998522349464, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6837827853712597, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6726399408830593, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.4916882157369782, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6542297746582934, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6323665250323296, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.48226819357222017, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6172885112670853, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6515795307592832, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.4811599556704839, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6677133357960843, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6373545169037502, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.4833764314739564, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6797192463982268, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l2, tol=0.1, score=0.6183262516164788, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.46915404506834135, total=   3.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5371259697081641, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.4636985036024386, total=   2.4s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5408200960472849, total=   4.5s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5340846111213745, total=   0.8s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.47210934613963795, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5374953823420761, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5370404581562904, total=   4.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5544883635020318, total=   0.3s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.01, score=0.4636985036024386, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5387883265607684, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5985590245704785, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.5349094939046916, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6104543775397119, total=   2.4s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6658045446148162, total=   2.9s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5240118212042851, total=   1.3s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6209826376062061, total=   2.7s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6052096803990393, total=   2.8s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.5110823790173624, total=   0.7s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.634281492427041, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.001, score=0.6528727138370589, total=   0.3s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.5199482822312523, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6433321019578869, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.01, score=0.6578607057084795, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.5182859253786479, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.601588474325822, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=squared_hinge, penalty=none, tol=0.1, score=0.6373545169037502, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.47857406723309937, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6808274842999631, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6336597081101053, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.4735869966752863, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.685075729589952, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6440051727323111, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.49279645363871444, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6719615810860732, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.001, score=0.6423425087751709, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.47801994828223127, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.680642777983007, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.01, score=0.6811380011084427, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.4774658293313631, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6675286294791282, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l2, tol=0.1, score=0.6423425087751709, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=1e-05, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.0001, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.001, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.01, score=0.4633290227230741, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5371259697081641, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.5192094569634281, total=   2.4s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.6582933136313261, total=   2.4s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=1e-05, score=0.673933123960835, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.523457702253417, total=   0.9s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6765792390099742, total=   1.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.0001, score=0.6600775909846666, total=   1.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.5245659401551533, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6536756557074251, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.001, score=0.6802142989100314, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.5059106021425933, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.6455485777613594, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.01, score=0.658230186587844, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.5175471001108238, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6466568156630956, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=balanced, loss=modified_huber, penalty=none, tol=0.1, score=0.6307038610751894, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5421130402659771, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5628001477650536, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=1e-05, score=0.5656752263070386, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5421130402659771, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.564647210934614, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.0001, score=0.5447995566229448, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5397118581455486, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.5570742519394163, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.001, score=0.574912248291151, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5411895086811969, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.5561507203546361, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.01, score=0.57565121004988, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5391577391946805, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5572589582563724, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l2, tol=0.1, score=0.5686310733419545, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=1e-05, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.4s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.0001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.01, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.47857406723309937, total=   2.5s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6660509789434799, total=   2.3s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=1e-05, score=0.6510253094402365, total=   2.3s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.4837458441078685, total=   0.4s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6642039157739195, total=   0.5s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.0001, score=0.6153704045815629, total=   0.6s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.4898411525674178, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6623568526043591, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.001, score=0.6107518935895068, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.4892870336165497, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6411156261544145, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.01, score=0.6428967300942177, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.4811599556704839, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.6117473217584042, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=hinge, penalty=none, tol=0.1, score=0.5867356364308147, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5393424455116365, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.569264868858515, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=1e-05, score=0.5673378902641788, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5456224602881419, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.564647210934614, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.0001, score=0.5732495843340107, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5439601034355375, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5583671961581086, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.001, score=0.5745427674117864, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5443295160694496, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5552271887698559, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.01, score=0.5752817291705155, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5411895086811969, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5663095677872183, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l2, tol=0.1, score=0.5762054313689267, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=1e-05, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.0001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.01, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.5040635389730329, total=   1.9s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6549685999261174, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=1e-05, score=0.6253463883244043, total=   2.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.4689693387513853, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6472109346139638, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.0001, score=0.6183262516164788, total=   0.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.4915035094200222, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.6479497598817879, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.001, score=0.5961573988546093, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.4948282231252309, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6326191355744366, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.01, score=0.6113061149085535, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.509420022164758, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.6374214998152937, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=log, penalty=none, tol=0.1, score=0.58470349159431, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.4708164019209457, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.6316956039896564, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=1e-05, score=0.612414557546647, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.4750646472109346, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.6784263021795346, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.0001, score=0.612414557546647, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.47857406723309937, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.5864425563354266, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.001, score=0.6125992979863292, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.47026228297007755, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6599556704839306, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.01, score=0.6107518935895068, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.48005171776874767, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.596786110084965, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l2, tol=0.1, score=0.620727877332348, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=1e-05, score=0.5355625346388324, total=   1.7s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5446989287033617, total=   0.4s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.0001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.4634281492427041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.001, score=0.5366709772769259, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5334318433690433, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5345400812707795, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.01, score=0.5385183816737484, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5160694495751754, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=l1, tol=0.1, score=0.5364862368372437, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.504617657923901, total=   2.4s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.6280014776505356, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=1e-05, score=0.657491224829115, total=   2.3s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.5158847432582194, total=   0.9s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6254155892131511, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.0001, score=0.6319970441529651, total=   2.2s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.514222386405615, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6329885482083487, total=   0.3s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.001, score=0.6140772215037872, total=   1.7s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.5151459179903952, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6322497229405246, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.01, score=0.6161093663402919, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.5166235685260436, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.6067602512005911, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=squared_hinge, penalty=none, tol=0.1, score=0.634213929429152, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.47210934613963795, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6538603620243812, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=1e-05, score=0.6161093663402919, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.4695234577022534, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6368673808644255, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.0001, score=0.6150009237021984, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.4763575914296269, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.6590321388991504, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.001, score=0.5976353223720673, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.4695234577022534, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.6224602881418545, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.01, score=0.5566229447626085, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.46786110084964905, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.6409309198374584, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l2, tol=0.1, score=0.5743580269721041, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=1e-05, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.0001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.001, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.01, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5365718507572959, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=l1, tol=0.1, score=0.5366709772769259, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.5206871074990764, total=   2.3s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6688215736978205, total=   2.2s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=1e-05, score=0.6624792167005358, total=   2.2s
/Users/frandm/anaconda3/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.5240118212042851, total=   1.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.6608792020687108, total=   1.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.0001, score=0.676888970995751, total=   0.8s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.514222386405615, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6629109715552272, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.001, score=0.6706077960465546, total=   0.1s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.5201329885482083, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6475803472478758, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.01, score=0.6667282468132274, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.5216106390838566, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6401920945696343, total=   0.0s
[CV] alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1 
[CV]  alpha=0.1, average=False, class_weight=None, loss=modified_huber, penalty=none, tol=0.1, score=0.6425272492148532, total=   0.0s
[Parallel(n_jobs=1)]: Done 3600 out of 3600 | elapsed: 58.4min finished
0.668062311
SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', max_iter=1000,
       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, tol=0.01, verbose=0, warm_start=False)
             precision    recall  f1-score   support

          0       0.79      0.83      0.81      2028
          1       0.82      0.78      0.80      2028

avg / total       0.80      0.80      0.80      4056


Process finished with exit code 0
